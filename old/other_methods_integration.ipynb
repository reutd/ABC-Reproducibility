{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZorHPTADBsyg8WOlzk6iBoN_gN0hDnee","timestamp":1683533089412},{"file_id":"1gBgf2mlEqX-W5mkHGd_kZKskkAtUZo7g","timestamp":1683458140797}],"gpuType":"V100","machine_shape":"hm","mount_file_id":"1dsmglxylLeqNhXQm-qk6eSlsgSWxF-n9","authorship_tag":"ABX9TyP0voS29V2sjAFqOUXnEyc7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install scanpy==1.9.1\n","!pip install tensorflow\n","!pip install matplotlib==3.6\n","!pip install scib\n","!pip install scanorama==1.7.0\n","\n","!pip install --quiet scvi-colab\n","!pip install --quiet scib-metrics\n","from scvi_colab import install\n","install()\n","\n","# ---------------------------------------------------------------------\n","# WHEN USING COLAB, PLEASE RESTART RUNTIME AFTER RUNNING THIS CELL\n","# ---------------------------------------------------------------------\n","\n","# (some of the packages being used in this notebook are automatically loaded \n","# before installation of a different version and they need to be reloaded)\n"],"metadata":{"id":"cMPrgehUBk-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rvp-ZZbxP-1I"},"outputs":[],"source":["# Most of the code was addapted from:\n","# https://github.com/theislab/scib\n","\n","import scvi\n","import os\n","from pathlib import Path\n","import scipy\n","import scanpy as sc\n","import scib\n","import numpy as np\n","from scib import utils\n","import time\n","import collections \n","import sys\n","import pandas as pd\n","if sys.version_info.major == 3 and sys.version_info.minor >= 10:\n","    from collections.abc import MutableSet\n","    collections.MutableSet = collections.abc.MutableSet\n","else: \n","    from collections import MutableSet\n","\n","# When using colab, set the path to the modules directory to use saved modules\n","sys.path.append('/content/drive/MyDrive/modules/')\n","from datasets_dict import datasets\n","\n","# The main integration function (calls the appropriate integration method)\n","def integrate(inPath, method, batchLabel, celltypeLabel=None):\n","\n","    # read the original dataset\n","    adata = sc.read(inPath)\n","    hvg = None\n","\n","    # integrate the dataset\n","    if celltypeLabel is not None:\n","        start_time = time.time()\n","        integrated = method(adata, batchLabel, hvg, celltypeLabel)\n","        end_time = time.time()\n","\n","    else:\n","        start_time = time.time()\n","        integrated = method(adata, batchLabel, hvg)\n","        end_time = time.time()\n","\n","    elapsed_time = end_time - start_time\n","\n","    return integrated, elapsed_time\n","\n","\n","def trvae(adata, batch_category):\n","\n","    conditions = adata.obs[batch_category].unique().tolist()\n","    network = trvae.archs.trVAEMulti(adata.shape[1], conditions,\n","                                 z_dimension=10,\n","                                 gene_names=adata.var_names.tolist(),\n","                                 architecture=[256, 64],\n","                                 model_path='./models/trVAE/haber/',\n","                                 alpha=0.0001,\n","                                 beta=50,\n","                                 eta=100,\n","                                 loss_fn='sse',\n","                                 output_activation='linear')\n","\n","    network.train(adata,\n","                  batch_category,\n","                  train_size=0.8,\n","                  n_epochs=50,\n","                  batch_size=512,\n","                  early_stop_limit=10,\n","                  lr_reducer=20,\n","                  verbose=5,\n","                  save=True,\n","                  )\n","    target_condition = adata.obs[batch_category].value_counts().index[0]\n","    corrected = network.predict(adata, batch_category, target_condition=target_condition)\n","\n","    return corrected\n","\n","\n","# Wrapper function for scib combat\n","def combat(adata, batch_category, hvg=None):\n","  return scib.integration.combat(adata, batch_category)\n","\n","\n","# integration procedure from the tutorial \"Integration with scVI\":\n","# https://docs.scvi-tools.org/en/stable/tutorials/notebooks/harmonization.html\n","def scviIntegration(adata, batch_category, hvg):\n","\n","    scvi.model.SCVI.setup_anndata(adata, layer=\"counts\", batch_key=batch_category)\n","    vae = scvi.model.SCVI(adata, n_layers=2, n_latent=30, gene_likelihood=\"nb\")\n","    vae.train()\n","    corrected = adata.copy()\n","    corrected.X = vae.get_normalized_expression()\n","    return corrected\n","\n","\n","def scanvi(adata, batch_category, hvg, label_key):\n","\n","    scvi.model.SCVI.setup_anndata(adata, layer=\"counts\", batch_key=batch_category)\n","    vae = scvi.model.SCVI(adata, n_layers=2, n_latent=30, gene_likelihood=\"nb\")\n","    vae.train()\n","\n","    lvae = scvi.model.SCANVI.from_scvi_model(\n","      vae,\n","      adata=adata,\n","      labels_key=label_key,\n","      unlabeled_category=\"Unknown\",\n","    )\n","\n","    lvae.train(max_epochs=20, n_samples_per_label=100)\n","    corrected = adata.copy()\n","    corrected.X = lvae.get_normalized_expression()\n","    return corrected\n","\n","\n","\n","# path to the original dataset (after subset to 3000 highly variable genes)\n","base_path = '/content/drive/MyDrive/Colab Notebooks/integrationDatasets/'\n","execution_times = {}\n","\n","methods = {    \n","        'scvi': scviIntegration,\n","        'scanvi': scanvi,\n","        'combat': combat,\n","        'scanorama': scib.integration.scanorama,\n","    }\n","\n","\n","for method in methods.keys():\n","  print(\"Integrating using method: \", method)\n","\n","  # for dataset_name in datasets.keys():\n","  for dataset_name in ['small_atac_windows']:\n","\n","    # get dataset parameters\n","    label_key = datasets[dataset_name]['label_key']\n","    batch_key = datasets[dataset_name]['batch_key']\n","\n","    # set paths\n","    inPath = os.path.join(base_path, f\"{dataset_name}_hvg.h5ad\")\n","    outPath = os.path.join(base_path, 'integratedDatasets', method)\n","    \n","    # create directory if does not exists\n","    Path(outPath).mkdir(parents=True, exist_ok=True)\n","    \n","    if method != 'scanvi':\n","      label_key = None\n","\n","\n","    # integrate the data\n","    integrated, elapsed_time = integrate(inPath, methods[method], \n","                                         batch_key, label_key)\n","\n","    # save integration duration time\n","    minutes, seconds = divmod(elapsed_time, 60)\n","    execution_times[dataset_name] = elapsed_time\n","\n","    print(\"Integrated: \", dataset_name)\n","    print(f\"Duration: {minutes} minutes and {seconds} seconds\")\n","    \n","    # write integrated data\n","    sc.write(os.path.join(outPath, f\"{dataset_name}_integrated.h5ad\"), integrated)\n","    print(\"Integrated data saved\")\n","\n","  # write execution times data\n","  df = pd.DataFrame(list(execution_times.items()), \n","                    columns=['Dataset', 'Execution Time'])\n","  df.to_csv(os.path.join(outPath, 'execution_times.csv'), index=False)\n","\n"]}]}